name: "Index datapackage"
description: "Installs a package and runs a python script"
inputs:
  token:
    description: "A Github PAT"
    required: true
  user:
    description: "AWS User ARN"
    required: true
  region:
    description: "AWS S3 Bucket Region"
    required: true
outputs:
  VALID_DATA:
    description: "Variable containing if data is valid or not"
    value: ${{ steps.set-valid-data.outputs.VALID_DATA }}
runs:
  using: "composite"
  steps:
    - name: Install dotoenv
      shell: bash
      run: pip3 install python-dotenv
    - name: Install frictionless
      shell: bash
      run: pip3 install frictionless
    - name: Install boto3
      shell: bash
      run: pip3 install boto3
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        role-to-assume: ${{inputs.user}}
        aws-region: ${{inputs.region}}
    - name: Copy data from S3 and Validate
      shell: bash
      id: set-valid-data
      if: always()
      run: |
        python .github/datahub-gh-actions/validate-data/sign_url.py >> datapackage.json
        VALID_DATA=$(python .github/datahub-gh-actions/validate-data/set_valid_data_flag.py)
        echo $VALID_DATA >> valid_data.txt
        echo "VALID_DATA=$VALID_DATA" >> $GITHUB_OUTPUT
    - name: Throw if data error
      shell: python
      if: always()
      run: |
        from frictionless import validate
        import os

        if os.path.isfile('datapackage.json'):
            report = validate('datapackage.json')
            print(report)
            if report['valid'] == False:
              exit(1)
            else:
              exit(0)
        else:
          exit(0)
    - name: Archive data validation results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: data-validation-result
        path: valid_data.txt
